#!/usr/bin/env python3

import argparse
import atexit
from collections.abc import Callable
import json
import multiprocessing
import re
import signal
import subprocess
import sys
import urllib.parse
from dataclasses import dataclass
from itertools import chain
from typing import TypeVar, Union

import cloudscraper
from bs4 import BeautifulSoup
from bs4.element import ResultSet

from python.downloaders import get_download_info, sort_download_links
from python.helpers.list import flatten
from python.helpers.main import get_episode_number_to_download, parse_arguments
from python.helpers.size import human_byte_size
from python.log.console import Chalk, Console

BASE_URL = "https://hianime.to"

ALLOWED_SERIES_TYPES = {
    "sub",
    "dub",
    "raw",
}

FORBIDDEN_CDN_URLS = {"ed.netmagcdn.com"}


def get_zoroto_page_url(anime_name: str) -> str:
    return f"{BASE_URL}/watch/{anime_name}"


def get_anime_id(anime_name: str) -> str | None:
    Console.log_dim("Extracting id from name", return_line=True)
    name_parts = anime_name.split("-")
    anime_id = name_parts[-1]
    if anime_id.isdigit():
        return anime_id
    Console.log_dim("Fetching episode page...", return_line=True)
    response = cloudscraper.create_scraper().get(
        get_zoroto_page_url(anime_name),
        headers={"User-Agent": "Zoro.to stream video downloader"},
    )

    if not response.status_code:
        Console.log_dim("Anime not found")
        return None

    page_html = response.text

    Console.log_dim("Parsing HTML...", return_line=True)

    try:
        info = BeautifulSoup(
            page_html,
            "html.parser",
        ).find(
            id="syncData",
        )

        if info is None:
            return None

        info = info.text

        return json.loads(info)["anime_id"]
    except Exception:
        return None


@dataclass
class EpisodeInfo:
    number: float
    title: str
    id: str
    url: str


def get_page(url: str):
    return cloudscraper.create_scraper().get(
        url,
        headers={
            "Accept": "*/*",
            "X-Requested-With": "XMLHttpRequest",
            "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36",
        },
    )


def get_anime_episode_list(anime_id: str) -> dict[float, EpisodeInfo]:
    Console.log_dim("Fetching episode list...", return_line=True)
    response = get_page(
        f"{BASE_URL}/ajax/v2/episode/list/{anime_id}",
    )

    if not response.status_code:
        Console.log_dim("No episodes found")
        return {}

    page_json = response.json()

    elements = BeautifulSoup(
        page_json["html"],
        "html.parser",
    ).find_all(
        class_="ep-item",
    )

    if not elements:
        Console.log_dim("No info found")
        return {}

    return {
        float(element.attrs["data-number"]): EpisodeInfo(
            id=element.attrs["data-id"],
            url=element.attrs["href"],
            number=float(element.attrs["data-number"]),
            title=element.attrs["title"],
        )
        for element in elements
    }


@dataclass
class DownloadServerInfo:
    type: str
    id: str
    server_id: str
    name: str


@dataclass
class DownloadInfo:
    name: str
    type: str
    url: str


def get_download_url_from_server_info(
    server: DownloadServerInfo,
) -> DownloadInfo | None:
    response = get_page(
        f"{BASE_URL}/ajax/v2/episode/sources?id={server.id}",
    )

    if not response.status_code:
        return None

    page_json = response.json()

    return DownloadInfo(
        name=server.name,
        type=server.type,
        url=page_json["link"],
    )


def get_anime_episode_download_server_list(
    episode: EpisodeInfo,
    series_type: Union[str, set] = "sub",
) -> list[DownloadInfo] | None:
    if isinstance(series_type, str):
        series_type = {series_type}

    Console.log_dim("Fetching download servers...", return_line=True)
    response = get_page(
        f"{BASE_URL}/ajax/v2/episode/servers?episodeId={episode.id}",
    )

    if not response.status_code:
        Console.log_dim("No download servers found")
        return None

    page_json = response.json()

    elements: ResultSet = BeautifulSoup(
        page_json["html"],
        "html.parser",
    ).find_all(
        class_="server-item",
    )

    servers_infos = {
        element.attrs["data-id"]: DownloadServerInfo(
            id=element.attrs["data-id"],
            name=next(element.stripped_strings),
            server_id=element.attrs["data-server-id"],
            type=element.attrs["data-type"],
        )
        for element in elements
    }

    Console.log_dim("Fetching list of source pages...", return_line=True)

    with multiprocessing.Pool() as pool:
        results = [
            item
            for item in pool.imap_unordered(
                get_download_url_from_server_info,
                servers_infos.values(),
            )
            if item and item.type in series_type
        ]

    return results


def main():
    Console.hide_cursor()
    atexit.register(Console.show_cursor)
    signal.signal(signal.SIGINT, lambda *_: sys.exit(0))
    signal.signal(signal.SIGTERM, lambda *_: sys.exit(0))
    signal.signal(signal.SIGHUP, lambda *_: sys.exit(0))

    def with_additional_args(parser: argparse.ArgumentParser):
        parser.add_argument(
            "-t --type",
            help="Whether to download the sub or dub",
            type=str,
            nargs="?",
            dest="series_type",
        )

        parser.add_argument(
            "-o, --offset",
            help="Set episode name offset (eg. -o 3 will name the first episode 4). Useful for when a season is split into multiple parts.",
            type=int,
            nargs="?",
            required=False,
            default=0,
            dest="offset",
        )

    argv = parse_arguments(site_name="zoro.to", extend=with_additional_args)

    series_name = argv.series_name or argv.series
    number_format = argv.number_format
    series_type = argv.series_type

    if series_name is None:
        raise Exception("No series name")

    if series_type not in ALLOWED_SERIES_TYPES:
        raise Exception(
            f"Invalid series type (must be one of: {', '.join(ALLOWED_SERIES_TYPES)})"
        )

    episode_number_offset = argv.offset
    episode_number = get_episode_number_to_download(argv) - episode_number_offset

    offset_str = (
        f" (offset episode {episode_number + episode_number_offset})"
        if episode_number_offset
        else ""
    )

    Console.log(
        f"Downloading {Chalk.badge(series_name, Chalk.black, Chalk.bg_yellow_bright)} episode {Chalk.badge(str(episode_number) + offset_str, Chalk.black, Chalk.bg_blue_bright)}"
    )

    anime_id = get_anime_id(series_name)
    if anime_id is None:
        Console.log_error(f"Can't fetch page for `{series_name}'")
        exit(1)

    episodes = get_anime_episode_list(anime_id)
    if episode_number not in episodes:
        Console.log_error(f"Episode {episode_number}{offset_str} can't be found")
        exit(1)

    if series_type == "sub":
        series_type = {"sub", "raw"}
    download_sites = get_anime_episode_download_server_list(
        episodes[episode_number], series_type
    )

    if not download_sites:
        Console.log_error(
            f"Couldn't download {episode_number}: No download servers found"
        )
        exit(1)

    sorted_download_site_urls = sort_download_links(
        download_sites,
        to_url=lambda x: x.url,
    )

    download_sites = {item.name: item.url for item in sorted_download_site_urls}

    Console.log_dim("Trying to find download link...", return_line=True)

    processed = 0
    for site in download_sites:
        processed += 1
        download_url = download_sites[site]
        try:
            download_info = get_download_info(
                download_url, get_zoroto_page_url(anime_name=series_name)
            )
            if download_info is None:
                raise Exception("No handler")

            url = download_info.url
            referer = download_info.referer or url
            output_file = (
                f"{number_format % (episode_number + episode_number_offset)}.mp4"
            )

            parsed_url = urllib.parse.urlparse(url)

            if parsed_url.hostname in FORBIDDEN_CDN_URLS:
                Console.log(
                    f"{Chalk.colour(Chalk.italic)}Skipping {site}: {url}{Chalk.colour('23m')}"
                )
                # continue

            Console.log(
                f"{Chalk.colour(Chalk.italic)}Downloading from {site}: {url}{Chalk.colour('23m')}"
            )

            Console.log_dim("Starting download...", return_line=True)
            download_cmd = [
                "yt-dlp",
                "--no-warnings",
                "--no-check-certificate",
                "--concurrent-fragments",
                "16",
                "--abort-on-unavailable-fragments",
                "--retries",
                "infinite",
                "--downloader",
                "ffmpeg",
                "--downloader-args",
                "-progress - -nostats",
                "--referer",
                referer,
                *list(
                    chain(
                        *[["--add-header", header] for header in download_info.headers]
                    )
                ),
                "--output",
                output_file,
                url,
            ]
            download_line_native = re.compile(r"\[download\]\s+(\d+\.\d+%.*)")

            with subprocess.Popen(
                download_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.DEVNULL,
                bufsize=1,
                text=True,
            ) as proc:
                Console.log_dim("Waiting for download progress...", return_line=True)
                for line in proc.stdout or []:
                    # if download_line_native.search(line):
                    #     status = line.split(" ", maxsplit=1)[1].strip()
                    #     Console.log_dim(status, return_line=True)
                    #     continue

                    # Read lines until status stuff comes along
                    if line[0] == "[":
                        continue
                    break

                # Read status block
                def s(key, pad=0, *, default="???") -> str:
                    return output_status_info.get(key, default).rjust(pad, " ")

                def s_if(key, pad=0, *, default="???"):
                    if key in output_status_info:
                        return s(key=key, pad=pad, default=default)
                    return None

                T = TypeVar("T")

                def chain_if(
                    initial: T | None, *processors: Callable[[T], T]
                ) -> T | None:
                    fns = flatten(processors)
                    for fn in fns:
                        if initial is None:
                            break
                        initial = fn(initial)
                    return initial

                def format_output():
                    out = []
                    for item in output_layout:
                        match item:
                            case dict():
                                for name, value in item.items():
                                    match value:
                                        case gen if callable(gen):
                                            res = gen()
                                            if res is not None:
                                                out.append(f"{name}={res}")
                                        case None:
                                            out.append(f"{name}")
                                        case value:
                                            out.append(f"{name}={value}")
                            case gen if callable(gen):
                                res = gen()
                                if res is not None:
                                    out.append(res)
                            case value:
                                out.append(str(value))
                    return " ".join(out)

                output_status_info = {}
                output_layout = [
                    {"time": lambda: s_if("out_time")},
                    "|",
                    {
                        "fps": lambda: s_if("fps", 6),
                        "speed": lambda: s_if("speed", 5),
                        "bitrate": lambda: s_if("bitrate", 6),
                    },
                    "|",
                    {
                        "size": lambda: chain_if(
                            s_if("total_size"),
                            lambda x: str(x).strip(),
                            lambda x: human_byte_size(x),
                        )
                    },
                ]
                while proc.poll() is None:
                    try:
                        for line in proc.stdout or []:
                            if line.startswith("progress="):
                                break
                            key, value = line.strip().split("=", maxsplit=1)
                            output_status_info[key.strip()] = value.strip()
                        Console.log_dim(
                            format_output(),
                            return_line=True,
                        )
                    except Exception:
                        pass

                if proc.wait() != 0:
                    print(subprocess.list2cmdline(download_cmd))
                    raise Exception("Something broke")

            download_info.after_dl(output_file, download_info)
        except Exception as e:
            if str(e) == "No handler":
                continue

            print(("\n" + "=" * 32) * 2)
            print(e)
            print(("=" * 32 + "\n") * 2)

        for _ in range(processed):
            Console.clear_line()
            Console.move_up(1)
        Console.log_success(f"Episode {episode_number} downloaded")
        exit()

    Console.clear_line()
    Console.move_up(processed)
    Console.log_error(
        f"Failed to download episode {episode_number}: No handlers succeeded"
    )
    exit(1)


if __name__ == "__main__":
    main()
